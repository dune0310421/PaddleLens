[
    {
        "repo": "PaddlePaddle/PaConvert",
        "number": 336,
        "title": "`torch.distributed.is_available()` and `torch.distributed.is_initialized()` cannot be converted",
        "body": "- `torch.distributed.is_available()`\r\n- `torch.distributed.is_initialized()`\r\n- `torch.distributed.get_world_size()`\r\n\r\n```python\r\nimport torch.distributed as dist\r\n\r\ndef is_dist_avail_and_initialized():\r\n    if not dist.is_available():\r\n        return False\r\n    if not dist.is_initialized():\r\n        return False\r\n    return True\r\n```",
        "state": "closed",
        "user": "GreatV",
        "closed_by": "GreatV",
        "created_at": "2023-11-30T02:52:08+00:00",
        "updated_at": "2024-02-05T02:21:47+00:00",
        "closed_at": "2024-02-05T02:21:47+00:00",
        "comments_count": [],
        "labels": [
            "PFCC"
        ]
    },
    {
        "repo": "PaddlePaddle/PaConvert",
        "number": 262,
        "title": "ã€ç¤¾åŒºæ²»ç†ã€‘co63oc å‘èµ· Committer èº«ä»½ç”³è¯·",
        "body": "### é—®é¢˜æè¿° Please describe your issue\r\n##### åŸºæœ¬ä¿¡æ¯\r\n| ç”³è¯·äºº GitHub ID | PaConvert Repo æ•´ä½“ merge PR æ•° | PaConvert Repo æ•´ä½“ review PR æ•° | PaConvert Repo æ•´ä½“æŠ¥å‘Š Issue æ•° |\r\n| - | - | - | - |\r\n| @co63oc | [50](https://github.com/PaddlePaddle/PaConvert/pulls?q=is%3Apr+author%3Aco63oc+is%3Aclosed) | 0 | 0 |\r\n\r\n##### ç¤¾åŒºè´¡çŒ®æ¦‚å†µ\r\nä»¥ä¸‹æ˜¯æ­¤å‰åœ¨æœ¬ repo é‡Œåšè¿‡çš„è´¡çŒ®ï¼š\r\nå®ç°è‹¥å¹²ç®—å­è½¬æ¢è§„åˆ™\r\n\r\n##### é«˜è´¨é‡ merge PR å±•ç¤º\r\n| PR å· | PR æ ‡é¢˜ | PR ç®€ä»‹ | Reviewer |\r\n| - | - | - | - |\r\n| #197 | è½¬æ¢è§„åˆ™ No. 196/197/232/233/319 | - | zhwesky2010 |\r\n| #198 | è½¬æ¢è§„åˆ™ No. 323/333 | - | zhwesky2010 |\r\n| #199 | è½¬æ¢è§„åˆ™ No. 349/350 | - | zhwesky2010 |\r\n\r\n##### æ‹…ä¿äººæ„è§\r\n@Ligoml @luotao1",
        "state": "closed",
        "user": "co63oc",
        "closed_by": "co63oc",
        "created_at": "2023-08-28T07:57:33+00:00",
        "updated_at": "2023-08-28T12:38:05+00:00",
        "closed_at": "2023-08-28T12:38:05+00:00",
        "comments_count": [
            "luotao1",
            "zhwesky2010",
            "zhwesky2010",
            "Ligoml"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaConvert",
        "number": 333,
        "title": "Conversion fails when `\\u` is in the code",
        "body": "**code**\r\n\r\n```python\r\nimport numpy as np\r\n\r\ndef extract_vertices(lines):\r\n\t'''extract vertices info from txt lines\r\n\tInput:\r\n\t\tlines   : list of string info\r\n\tOutput:\r\n\t\tvertices: vertices of text regions <numpy.ndarray, (n,8)>\r\n\t\tlabels  : 1->valid, 0->ignore, <numpy.ndarray, (n,)>\r\n\t'''\r\n\tlabels = []\r\n\tvertices = []\r\n\tfor line in lines:\r\n\t\tvertices.append(list(map(int,line.rstrip('\\n').lstrip('\\ufeff').split(',')[:8])))\r\n\t\tlabel = 0 if '###' in line else 1\r\n\t\tlabels.append(label)\r\n\treturn np.array(vertices), np.array(labels)\r\n\r\n```\r\n\r\n**output**\r\n\r\n```\r\npython paconvert/main.py --in_dir ~/repos/bug_test/ --out_dir ~/repos/bug_test_\r\n===========================================\r\nPyTorch to Paddle Convert Start ------>:\r\n===========================================\r\nStart convert file: /home/greatx/repos/bug_test/test.py --> /home/greatx/repos/bug_test_/test.py\r\nTraceback (most recent call last):\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/sre_parse.py\", line 1051, in parse_template\r\n    this = chr(ESCAPES[this][1])\r\nKeyError: '\\\\u'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/greatx/repos/PaConvert/paconvert/main.py\", line 145, in <module>\r\n    main()\r\n  File \"/home/greatx/repos/PaConvert/paconvert/main.py\", line 131, in main\r\n    converter.run(args.in_dir, args.out_dir, args.exclude_dirs)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/converter.py\", line 88, in run\r\n    self.transfer_dir(in_dir, out_dir, exclude_dir_list)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/converter.py\", line 186, in transfer_dir\r\n    self.transfer_dir(old_path, new_path, exclude_dir_list)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/converter.py\", line 164, in transfer_dir\r\n    self.transfer_file(old_path, new_path)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/converter.py\", line 202, in transfer_file\r\n    self.transfer_node(root, old_path)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/converter.py\", line 242, in transfer_node\r\n    trans.transform()\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/base.py\", line 81, in transform\r\n    self.visit(self.root)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/base.py\", line 86, in visit\r\n    node = super(BaseTransformer, self).visit(node)\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/ast.py\", line 418, in visit\r\n    return visitor(node)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/base.py\", line 295, in visit_Module\r\n    super(BaseTransformer, self).generic_visit(node)\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/ast.py\", line 494, in generic_visit\r\n    value = self.visit(value)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/base.py\", line 86, in visit\r\n    node = super(BaseTransformer, self).visit(node)\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/ast.py\", line 418, in visit\r\n    return visitor(node)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/base.py\", line 247, in visit_FunctionDef\r\n    super(BaseTransformer, self).generic_visit(node)\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/ast.py\", line 494, in generic_visit\r\n    value = self.visit(value)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/base.py\", line 86, in visit\r\n    node = super(BaseTransformer, self).visit(node)\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/ast.py\", line 418, in visit\r\n    return visitor(node)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/base.py\", line 277, in visit_For\r\n    super(BaseTransformer, self).generic_visit(node)\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/ast.py\", line 494, in generic_visit\r\n    value = self.visit(value)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/base.py\", line 86, in visit\r\n    node = super(BaseTransformer, self).visit(node)\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/ast.py\", line 418, in visit\r\n    return visitor(node)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/transformer/basic_transformer.py\", line 666, in visit_Expr\r\n    new_node = self.visit(old_value)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/base.py\", line 86, in visit\r\n    node = super(BaseTransformer, self).visit(node)\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/ast.py\", line 418, in visit\r\n    return visitor(node)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/transformer/basic_transformer.py\", line 363, in visit_Call\r\n    super(BasicTransformer, self).generic_visit(node)\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/ast.py\", line 494, in generic_visit\r\n    value = self.visit(value)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/base.py\", line 86, in visit\r\n    node = super(BaseTransformer, self).visit(node)\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/ast.py\", line 418, in visit\r\n    return visitor(node)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/transformer/basic_transformer.py\", line 363, in visit_Call\r\n    super(BasicTransformer, self).generic_visit(node)\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/ast.py\", line 494, in generic_visit\r\n    value = self.visit(value)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/base.py\", line 86, in visit\r\n    node = super(BaseTransformer, self).visit(node)\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/ast.py\", line 418, in visit\r\n    return visitor(node)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/transformer/basic_transformer.py\", line 363, in visit_Call\r\n    super(BasicTransformer, self).generic_visit(node)\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/ast.py\", line 494, in generic_visit\r\n    value = self.visit(value)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/base.py\", line 86, in visit\r\n    node = super(BaseTransformer, self).visit(node)\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/ast.py\", line 418, in visit\r\n    return visitor(node)\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/ast.py\", line 503, in generic_visit\r\n    new_node = self.visit(old_value)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/base.py\", line 86, in visit\r\n    node = super(BaseTransformer, self).visit(node)\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/ast.py\", line 418, in visit\r\n    return visitor(node)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/transformer/basic_transformer.py\", line 539, in visit_Call\r\n    return self.trans_class_method(node, torch_class_api)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/transformer/basic_transformer.py\", line 556, in trans_class_method\r\n    node_list = matcher.get_paddle_class_nodes(\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/base.py\", line 508, in get_paddle_class_nodes\r\n    self.parse_func(func)\r\n  File \"/home/greatx/repos/PaConvert/paconvert/../paconvert/base.py\", line 390, in parse_func\r\n    new_paddle_api = re.sub(\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/re.py\", line 209, in sub\r\n    return _compile(pattern, flags).sub(repl, string, count)\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/re.py\", line 326, in _subx\r\n    template = _compile_repl(template, pattern)\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/re.py\", line 317, in _compile_repl\r\n    return sre_parse.parse_template(repl, pattern)\r\n  File \"/home/greatx/miniconda3/envs/jit-env/lib/python3.10/sre_parse.py\", line 1054, in parse_template\r\n    raise s.error('bad escape %s' % this, len(this))\r\nre.error: bad escape \\u at position 26\r\n```",
        "state": "closed",
        "user": "GreatV",
        "closed_by": "GreatV",
        "created_at": "2023-11-21T15:47:56+00:00",
        "updated_at": "2023-11-27T04:04:44+00:00",
        "closed_at": "2023-11-27T04:04:44+00:00",
        "comments_count": [
            "RedContritio"
        ],
        "labels": [
            "contributor",
            "PFCC"
        ]
    },
    {
        "repo": "PaddlePaddle/PaConvert",
        "number": 340,
        "title": "got the wrong result when using paconvet",
        "body": "- pytorch\r\n\r\n```python\r\nimport torch.nn as nn\r\nfrom functools import partial\r\n\r\n\r\nclass test(nn.Module):\r\n    def __init__(self, in_channels, out_channels, norm_func=nn.LayerNorm):\r\n        super(test, self).__init__()\r\n        self.norm = norm_func(in_channels)\r\n        self.linear = nn.Linear(in_channels, out_channels)\r\n    \r\n    def forward(self, x):\r\n        x = self.norm(x)\r\n        x = self.linear(x)\r\n        return x\r\n\r\nif __name__ == \"__main__\":\r\n    model = test(10, 10, partial(nn.LayerNorm, eps=0.2))\r\n```\r\n\r\n- paddle\r\n\r\n```python\r\nimport paddle\r\nfrom functools import partial\r\n\r\n\r\nclass test(paddle.nn.Layer):\r\n\r\n    def __init__(self, in_channels, out_channels, norm_func=paddle.nn.LayerNorm\r\n        ):\r\n        super(test, self).__init__()\r\n        self.norm = norm_func(in_channels)\r\n        self.linear = paddle.nn.Linear(in_features=in_channels,\r\n            out_features=out_channels)\r\n\r\n    def forward(self, x):\r\n        x = self.norm(x)\r\n        x = self.linear(x)\r\n        return x\r\n\r\n\r\nif __name__ == '__main__':\r\n    model = test(10, 10, partial(paddle.nn.LayerNorm, eps=0.2))\r\n\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/greatx/repos/PaConvert/paddle_project/test.py\", line 21, in <module>\r\n    model = test(10, 10, partial(paddle.nn.LayerNorm, eps=0.2))\r\n  File \"/home/greatx/repos/PaConvert/paddle_project/test.py\", line 10, in __init__\r\n    self.norm = norm_func(in_channels)\r\nTypeError: LayerNorm.__init__() got an unexpected keyword argument 'eps'\r\n```\r\n\r\n**`eps` should be converted to `epsilon`.**",
        "state": "open",
        "user": "GreatV",
        "closed_by": "GreatV",
        "created_at": "2023-12-03T02:41:15+00:00",
        "updated_at": "2024-06-05T09:33:18+00:00",
        "closed_at": null,
        "comments_count": [
            "zhwesky2010",
            "GreatV",
            "zhwesky2010"
        ],
        "labels": [
            "PFCC"
        ]
    },
    {
        "repo": "PaddlePaddle/PaConvert",
        "number": 337,
        "title": "got the wrong result when using paconvet",
        "body": " - Pytorch\r\n \r\n```python\r\nimport torch.backends.cudnn as cudnn\r\n\r\ncudnn.benchmark = True\r\n```\r\n\r\n- Paddle\r\n\r\n```python\r\nimport paddle\r\n\r\nFalse = True\r\n```",
        "state": "open",
        "user": "GreatV",
        "closed_by": "GreatV",
        "created_at": "2023-11-30T05:22:24+00:00",
        "updated_at": "2024-06-05T09:37:00+00:00",
        "closed_at": null,
        "comments_count": [
            "RedContritio",
            "zhwesky2010",
            "GreatV"
        ],
        "labels": [
            "PFCC"
        ]
    },
    {
        "repo": "PaddlePaddle/PaConvert",
        "number": 255,
        "title": "torch_scatteråº“çš„paddleè½¬æ¢",
        "body": "[torch_scatter](https://github.com/rusty1s/pytorch_scatter) æ˜¯ä¸€ä¸ªtorchçš„æ‰©å¢åº“ï¼Œç›®å‰åœ¨ç§‘å­¦è®¡ç®—ã€ç¥ç»è¾å°„åœºç­‰é¢†åŸŸå‡æœ‰ç”¨åˆ°ï¼Œä¾‹å¦‚ç¬¬å››æœŸé»‘å®¢æ¾çš„èµ›é¢˜[No.173 Point-NeRF](https://github.com/PaddlePaddle/community/blob/master/hackthon_4th/%E3%80%90PaddlePaddle%20Hackathon%204%E3%80%91%20%E6%A8%A1%E5%9E%8B%E5%A5%97%E4%BB%B6%E5%BC%80%E6%BA%90%E8%B4%A1%E7%8C%AE%E4%BB%BB%E5%8A%A1%E5%90%88%E9%9B%86.md#task173)å°±æ¶‰åŠtorch_scatterä¸­çš„scatter_minç®—å­ï¼Œæ— æ³•é€šè¿‡paddleå¤ç°ï¼Œåƒç®€å•çš„scatter_addå€’æ˜¯å¯ä»¥ç»„åˆå¤ç°ï¼Œä½†æ˜¯ä¹Ÿå¾ˆå¤§çš„å¢åŠ äº†å¤ç°çš„æˆæœ¬ã€‚è¯·é—®æ‚¨è¿™è¾¹æœ‰è®¡åˆ’æ¨å‡ºtorch_scatterçš„paddleè½¬æ¢å—",
        "state": "closed",
        "user": "kongdebug",
        "closed_by": "kongdebug",
        "created_at": "2023-08-26T05:59:46+00:00",
        "updated_at": "2023-08-29T01:45:37+00:00",
        "closed_at": "2023-08-29T01:45:37+00:00",
        "comments_count": [
            "GreatV",
            "kongdebug"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaConvert",
        "number": 304,
        "title": "Torch code è½¬ Paddle code å¤±è´¥",
        "body": "ä½¿ç”¨å‘½ä»¤`pytest tests/test_cummin.py`æµ‹è¯•æµ‹è¯•æ¡ˆä¾‹æ—¶å¤±è´¥ï¼Œå‘ç°åœ¨`test_project/paddle_temp.py`ä¸­çš„ä»£ç æ²¡æœ‰æ›´æ”¹ä¸ºPaddle codeï¼Œè¯·é—®è¯¥å¦‚ä½•è§£å†³è¯¥é—®é¢˜ã€‚\r\n\r\næŠ¥é”™ä¿¡æ¯å¦‚ä¸‹ï¼š\r\n```\r\n================================================= test session starts =================================================\r\nplatform win32 -- Python 3.9.18, pytest-7.4.2, pluggy-1.3.0 -- D:\\anaconda2\\envs\\hackthon\\python.exe\r\ncachedir: .pytest_cache\r\nrootdir: C:\\Users\\lfy\\Desktop\\PaConvert\\tests\r\nconfigfile: pytest.ini\r\nplugins: anyio-4.0.0, cov-4.1.0\r\ncollected 1 item\r\n\r\ntests\\test_cummin.py::test_case_1 FAILED\r\n\r\n====================================================== FAILURES =======================================================\r\n_____________________________________________________ test_case_1 _____________________________________________________\r\n\r\n    def test_case_1():\r\n        pytorch_code = textwrap.dedent(\r\n            \"\"\"\r\n            import torch\r\n            x = torch.tensor([[1.0, 1.0, 1.0],\r\n                            [2.0, 2.0, 2.0],\r\n                            [3.0, 3.0, 3.0]])\r\n            result = torch.cummin(x, 0)\r\n            \"\"\"\r\n        )\r\n>       obj.run(pytorch_code, [\"result\"])\r\n\r\ntests\\test_cummin.py:32:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\ntests\\apibase.py:89: in run\r\n    self.compare(\r\ntests\\apibase.py:165: in compare\r\n    self.compare(\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nself = <apibase.APIBase object at 0x0000024B5A25EF70>, name = 'torch.cummin'\r\npytorch_result = tensor([[1., 1., 1.],\r\n        [1., 1., 1.],\r\n        [1., 1., 1.]])\r\npaddle_result = tensor([[1., 1., 1.],\r\n        [1., 1., 1.],\r\n        [1., 1., 1.]]), check_value = True\r\ncheck_dtype = True, check_stop_gradient = True, rtol = 1e-06, atol = 0.0\r\n\r\n    def compare(\r\n        self,\r\n        name,\r\n        pytorch_result,\r\n        paddle_result,\r\n        check_value=True,\r\n        check_dtype=True,\r\n        check_stop_gradient=True,\r\n        rtol=1.0e-6,\r\n        atol=0.0,\r\n    ):\r\n        \"\"\"\r\n        compare tensors' data, shape, requires_grad, dtype\r\n        args:\r\n            name: pytorch api name\r\n            pytorch_result: pytorch Tensor\r\n            paddle_result: paddle Tensor\r\n            check_value: If false, the value will not be checked\r\n            check_dtype: If false, the dtype will not be checked\r\n            check_stop_gradient: If false, the stop gradient will not be checked\r\n        \"\"\"\r\n        if isinstance(pytorch_result, dict):\r\n            assert isinstance(paddle_result, dict), \"paddle result should be dict\"\r\n            assert len(pytorch_result) == len(\r\n                paddle_result\r\n            ), \"paddle result have different length with pytorch\"\r\n            pytorch_result_k = [k for k in pytorch_result.keys()]\r\n            pytorch_result_v = [v for v in pytorch_result.values()]\r\n            paddle_result_k = [k for k in paddle_result.keys()]\r\n            paddle_result_v = [v for v in paddle_result.values()]\r\n            self.compare(\r\n                self.pytorch_api,\r\n                pytorch_result_k,\r\n                paddle_result_k,\r\n                check_value,\r\n                check_dtype,\r\n                check_stop_gradient,\r\n                rtol,\r\n                atol,\r\n            )\r\n            self.compare(\r\n                self.pytorch_api,\r\n                pytorch_result_v,\r\n                paddle_result_v,\r\n                check_value,\r\n                check_dtype,\r\n                check_stop_gradient,\r\n                rtol,\r\n                atol,\r\n            )\r\n            return\r\n\r\n        if isinstance(pytorch_result, (tuple, list)):\r\n            assert isinstance(\r\n                paddle_result, (tuple, list)\r\n            ), \"paddle result should be list/tuple\"\r\n            assert len(pytorch_result) == len(\r\n                paddle_result\r\n            ), \"paddle result have different length with pytorch\"\r\n            for i in range(len(pytorch_result)):\r\n                self.compare(\r\n                    self.pytorch_api,\r\n                    pytorch_result[i],\r\n                    paddle_result[i],\r\n                    check_value,\r\n                    check_dtype,\r\n                    check_stop_gradient,\r\n                    rtol,\r\n                    atol,\r\n                )\r\n            return\r\n\r\n        if isinstance(pytorch_result, (bool, np.number, int, str, type(None))):\r\n            assert type(paddle_result) == type(\r\n                pytorch_result\r\n            ), \"paddle result's type [{}] should be the same with pytorch's type [{}]\".format(\r\n                type(paddle_result), type(pytorch_result)\r\n            )\r\n            if check_value:\r\n                assert (\r\n                    pytorch_result == paddle_result\r\n                ), \"API ({}): pytorch result is {}, but paddle result is {}\".format(\r\n                    name, pytorch_result, paddle_result\r\n                )\r\n            return\r\n\r\n        if pytorch_result.requires_grad:\r\n            pytorch_numpy, paddle_numpy = (\r\n                pytorch_result.detach().numpy(),\r\n                paddle_result.numpy(False),\r\n            )\r\n        elif pytorch_result.is_conj():\r\n            pytorch_numpy, paddle_numpy = (\r\n                pytorch_result.resolve_conj().numpy(),\r\n                paddle_result.numpy(False),\r\n            )\r\n        else:\r\n            (\r\n                pytorch_numpy,\r\n                paddle_numpy,\r\n>           ) = pytorch_result.cpu().numpy(), paddle_result.numpy(False)\r\nE           TypeError: numpy() takes 0 positional arguments but 1 was given\r\n\r\ntests\\apibase.py:205: TypeError\r\n-------------------------------------------------- Captured log call --------------------------------------------------\r\nINFO     Converter_0:utils.py:91 ===========================================\r\nINFO     Converter_0:utils.py:91 PyTorch to Paddle Convert Start ------>:\r\nINFO     Converter_0:utils.py:91 ===========================================\r\nINFO     Converter_0:utils.py:91 Start convert file: C:\\Users\\lfy\\Desktop\\PaConvert\\test_project\\pytorch_temp.py --> C:\\Users\\lfy\\Desktop\\PaConvert\\test_project\\paddle_temp.py\r\nINFO     Converter_0:utils.py:91 Finish convert C:\\Users\\lfy\\Desktop\\PaConvert\\test_project\\pytorch_temp.py --> C:\\Users\\lfy\\Desktop\\PaConvert\\test_project\\paddle_temp.py\r\n\r\nINFO     Converter_0:utils.py:91\r\n===========================================\r\nINFO     Converter_0:utils.py:91 Convert Summary:\r\nINFO     Converter_0:utils.py:91 ===========================================\r\nINFO     Converter_0:utils.py:91 There are 0 Pytorch APIs in this Project:\r\nINFO     Converter_0:utils.py:91  0  Pytorch APIs have been converted to Paddle successfully!\r\nINFO     Converter_0:utils.py:91  0  Pytorch APIs are not supported to convert to Paddle currently!\r\nINFO     Converter_0:utils.py:91  Convert Rate is: 0.000%\r\nINFO     Converter_0:utils.py:91\r\nThank you to use Paddle Code Convert Tool. You can make any suggestions to us.\r\n=============================================== short test summary info ===============================================\r\nFAILED tests\\test_cummin.py::test_case_1 - TypeError: numpy() takes 0 positional arguments but 1 was given\r\n================================================== 1 failed in 3.25s ==================================================\r\n\r\n```",
        "state": "closed",
        "user": "Li-fAngyU",
        "closed_by": "Li-fAngyU",
        "created_at": "2023-09-26T12:19:01+00:00",
        "updated_at": "2023-09-26T14:55:29+00:00",
        "closed_at": "2023-09-26T14:55:29+00:00",
        "comments_count": [
            "Li-fAngyU"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaConvert",
        "number": 112,
        "title": "Pytorch-Paddleä»£ç è½¬æ¢å·¥å…·å¼€æºä»»åŠ¡",
        "body": "## âœ¨ **é—®é¢˜æè¿°**ï¼š\r\n\r\nå¤§å®¶å¥½ï¼Œä¸ºäº†å®ç°å°† PyTorch ä»£ç è‡ªåŠ¨åŒ–çš„è½¬å†™æˆ Paddle ä»£ç ï¼Œä»è€Œæå‡æ¨¡å‹è¿ç§»çš„æ•ˆç‡ï¼Œæˆ‘ä»¬å»ºè®¾äº† [**ä»£ç è‡ªåŠ¨è½¬æ¢å·¥å…·**](https://github.com/PaddlePaddle/PaConvert): **Pa**ddlePaddle Code **Convert** Toolkitsï¼Œç›®å‰å·²æ”¯æŒäº†1000+ä¸ªPytorch APIçš„è‡ªåŠ¨è½¬æ¢ï¼Œæˆ‘ä»¬æ­¤æ¬¡å¯¹å¤–å¼€æ”¾**408ä¸ªAPIçš„è½¬æ¢è§„åˆ™å¼€å‘**ï¼Œæ¬¢è¿å¤§å®¶æ PR æ¥ä¸€èµ·æ”¯æŒè‡ªåŠ¨è½¬æ¢ ğŸ‰ğŸ‰ğŸ‰ã€‚\r\n\r\né€šè¿‡æœ¬æ¬¡æ´»åŠ¨ï¼Œä½ å¯ä»¥æ›´è¯¦ç»†åœ°äº†è§£ PyTorch æ¡†æ¶ä¸ Paddle æ¡†æ¶ç”¨æ³•åŠè®¾è®¡å·®å¼‚ï¼Œæå‡è‡ªå·±å¯¹æ·±åº¦å­¦ä¹ æ¡†æ¶çš„ç†Ÿæ‚‰ç¨‹åº¦ã€‚\r\n\r\n## ğŸ» **ä½ éœ€è¦åšçš„æ˜¯**ï¼š\r\n\r\næˆ‘ä»¬å·²å°†ä»»åŠ¡è®°å½•åœ¨[ã€Šåœ¨çº¿ä»»åŠ¡æ˜ç»†è¡¨ã€‹](https://shimo.im/sheets/RKAWVnVNopC1NKk8/1ihYi)ï¼Œä¸ºæ–¹ä¾¿å¤§å®¶è‡ªç”±é€‰æ‹©æ‰€ç†Ÿæ‚‰çš„APIï¼Œæ­¤æ¬¡ä¸å¯¹APIè¿›è¡Œåˆ†ç»„ï¼Œå¤§å®¶å¯è‡ªç”±é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªAPIæ¥å®ç°è‡ªåŠ¨è½¬æ¢ï¼Œè®¤é¢†æ—¶ç›´æ¥åœ¨æœ¬issueä¸‹å›å¤è®¤é¢†çš„**ä»»åŠ¡ID**ï¼ˆè‡³å°‘1ä¸ªï¼Œå»ºè®®ä¸€æ¬¡è®¤é¢†å¤šä¸ªï¼Œä¸”è¶Šå¤šçº¦å¥½ï¼‰ã€‚æ¬¢è¿å¤§å®¶è®¤é¢†ä»»åŠ¡å’Œæ PR~\r\n\r\n1. Fork [PaddlePaddle/docs](https://github.com/PaddlePaddle/docs) ã€[PaddlePaddle/PaConvert](https://github.com/PaddlePaddle/PaConvert) ä¸¤ä¸ªGithub Reopã€‚\r\n\r\n2. **ä¹¦å†™APIæ˜ å°„å…³ç³»**ï¼šPRæäº¤åˆ° [PaddlePaddle/docs](https://github.com/PaddlePaddle/docs) ä¸‹ï¼Œéœ€è¦ä¸ºæ¯ä¸ª API æ–°å¢å¯¹åº”çš„ md æ–‡ä»¶å¹¶æ”¾å…¥`docs/guides/model_convert/convert_from_pytorch/api_difference` å¯¹åº”çš„ç›®å½•ä¸‹ï¼Œæ–‡ä»¶åä¸ºPyTorch APIåã€‚å¦‚æœå·²å­˜åœ¨è¯¥APIçš„æ˜ å°„å…³ç³»ï¼Œåˆ™æ— éœ€æ–°å¢ md æ–‡ä»¶ï¼Œåªéœ€è¦**æ£€æŸ¥å¹¶æ ¡æ­£ä¹‹å‰çš„æ–‡æ¡£æ˜¯å¦æ­£ç¡®ï¼Œå¦‚æœä¸åé¢çš„ASTè§„åˆ™æœ‰å·®å¼‚ï¼Œåˆ™éœ€è¦ä¿®æ”¹æ–‡æ¡£**ã€‚\r\n\r\n3. APIæ˜ å°„å…³ç³»è¯·å‚è€ƒ [ã€ŠAPIæ˜ å°„å…³ç³»-æ ¼å¼è§„èŒƒã€‹](https://github.com/PaddlePaddle/docs/blob/develop/docs/guides/model_convert/convert_from_pytorch/api_difference/pytorch_api_mapping_format_cn.md) ï¼ŒPRæ ‡é¢˜æ ¼å¼ï¼š**æ˜ å°„æ–‡æ¡£ No. xxx/yyy/zzz**ï¼ŒPRæè¿°é™„ä¸Šæœ¬issueã€‚**è¯·ä¸¥æ ¼æ ¹æ®æ ¼å¼è§„èŒƒæ¥ä¹¦å†™æ–‡æ¡£ï¼Œé¿å…å› æ ¼å¼é—®é¢˜å¢åŠ ä¸å¿…è¦çš„reviewæˆæœ¬ï¼Œä¸æ»¡è¶³æ ¼å¼è§„èŒƒçš„PRå°†ä¸äºˆåˆå…¥**ã€‚\r\n\r\n4. APIæ˜ å°„å…³ç³»ç›¸å½“äºäººå·¥è½¬æ¢çš„æ€è·¯ï¼Œåœ¨å…¶å®Œæˆåï¼Œå³å¯**å¼€å‘ASTè‡ªåŠ¨è½¬æ¢è§„åˆ™**ï¼šå‚è€ƒ[ã€ŠASTè½¬æ¢è§„åˆ™å¼€å‘æ­¥éª¤ã€‹](https://github.com/PaddlePaddle/PaConvert/blob/master/docs/CONTRIBUTING.md#%E5%A6%82%E4%BD%95%E8%B4%A1%E7%8C%AE%E4%BB%A3%E7%A0%81) ä¸­æ­¥éª¤3~5ï¼ŒPRæ ‡é¢˜æ ¼å¼ï¼š**è½¬æ¢è§„åˆ™ No. xxx/yyy/zzz**ï¼ŒPRæè¿°é™„ä¸Šæœ¬issueä¸ä¸Šè¿°æ–‡æ¡£PRã€‚**è¯·ä¸¥æ ¼æ ¹æ®æ–‡æ¡£è¦æ±‚æ¥å¼€å‘ä»£ç ï¼Œé¿å…å¢åŠ ä¸å¿…è¦çš„reviewæˆæœ¬ï¼Œä¸æ»¡è¶³è¦æ±‚çš„PRå°†ä¸äºˆåˆå…¥ã€‚**\r\n\r\n5. æ¯1ä¸ªä»»åŠ¡**No.xxx** å‡åŒ…å« **1ä¸ªæ˜ å°„å…³ç³»æ–‡æ¡£PR + 1ä¸ªè½¬æ¢è§„åˆ™PR**ï¼Œä¸¤è€…å‡åˆå…¥è¯¥ä»»åŠ¡æ‰ç®—å®Œæˆï¼Œè¯·å°½å¯èƒ½ä¸€æ¬¡æ€§æäº¤å¤šä¸ªä»»åŠ¡ï¼Œä»¥æé«˜reviewæ•ˆç‡ã€‚\r\n\r\n6. reviewæ–¹å¼ï¼šè¯„è®ºé‡Œ @zhwesky2010 reviewï¼Œè¯·åŠæ—¶ä¿®æ”¹reviewæ„è§ï¼Œreviewé€šè¿‡åå°†åˆå…¥ä»£ç ã€‚\r\n\r\n## âœ¨ æ³¨ï¼š\r\n\r\n1. **è¯¥ä»»åŠ¡æ—¶é—´ï¼šPR æˆªæ­¢åˆå…¥æ—¶é—´æ˜¯2023/10/30ã€‚**\r\n\r\n2. è®¤é¢†è§„åˆ™ï¼šç›´æ¥åœ¨ issue ä¸‹å›å¤è®¤é¢†çš„**ä»»åŠ¡ ID**ï¼ˆå»ºè®®ä¸€æ¬¡è®¤é¢†å¤šä¸ªï¼‰ã€‚\r\n\r\n3. æäº¤PRå‰è¯·å‚ç…§[å®˜ç½‘](https://www.paddlepaddle.org.cn/documentation/docs/zh/dev_guides/code_contributing_path_cn.html)å®‰è£…pre-commitï¼Œæ£€æŸ¥ä»£ç æ ¼å¼ã€‚å¦åˆ™CIå¯èƒ½æ— æ³•é€šè¿‡ã€‚\r\n\r\n4. **PRè¯·å…ˆé€šè¿‡CIæ£€æŸ¥åå†å‘èµ·reviewï¼Œé¿å…å¢åŠ ä¸å¿…è¦çš„reviewæˆæœ¬ã€‚**\r\n\r\n5. PRæ ‡é¢˜æ ¼å¼ï¼š**æ˜ å°„æ–‡æ¡£ No. xxx/yyy/zzz**ï¼Œ**è½¬æ¢è§„åˆ™ No. xxx/yyy/zzz**ï¼ŒPRæè¿°å‡éœ€é™„ä¸Šæœ¬issueï¼Œåè€…PRæè¿°çš„ `PR Docs` é‡Œéœ€è¦å†™ä¸Šå‰è€…PRçš„é“¾æ¥ã€‚\r\n\r\n6. å¦‚æœè¯¥APIåœ¨paddleä¸­å­˜åœ¨ **åŠŸèƒ½ç¼ºå¤±ã€åŠŸèƒ½Bugã€åŠŸèƒ½diff** ç­‰é—®é¢˜ï¼Œå¯¼è‡´æ— æ³•è½¬æ¢ï¼Œè¯·ç›´æ¥åœ¨æœ¬issueä¸‹å›å¤ã€‚æˆ‘ä»¬ä¼šå®šæœŸç¡®è®¤å¹¶è®°å½•APIåŠŸèƒ½é—®é¢˜ï¼ŒåŒæ—¶å¯¹äºæ­¤é—®é¢˜ç‚¹ï¼Œå¯æš‚ä¸å¼€å‘Matcherä½†ä»éœ€å¼€å‘ **å±è”½ç‰ˆæœ¬çš„æµ‹è¯•case**ï¼ˆå•æµ‹å±è”½æ–¹å¼å¯æŸ¥è¯¢å¼€å‘æ–‡æ¡£æˆ–å‚è€ƒå·²æœ‰å•æµ‹çš„ä»£ç ï¼‰ã€‚é—®é¢˜æè¿°å‚è€ƒå¦‚ä¸‹æ ¼å¼ï¼š\r\n    - `torch.diff` é—®é¢˜ï¼špaddleä»…æ”¯æŒn=1ï¼Œtorchçš„nå¯æ”¯æŒä»»æ„å€¼\r\n    -  `torch.nonzero` é—®é¢˜ï¼šæŒ‡å®šas_tupleæ—¶è¡Œä¸ºä¸ä¸€è‡´ï¼Œpaddleä¼šå¤šä¸€ç»´ä¸”ä¸åˆç† \r\n    - `torch.dstack` é—®é¢˜ï¼šåŠŸèƒ½ç¼ºå¤±\r\n\r\n7. **ä»»åŠ¡æ˜ç»†è¡¨ä¸­å·²å¯¹æ˜ å°„å…³ç³»çš„åˆ†ç±»è¿›è¡Œäº†åˆæ­¥ç²—ç•¥æ ‡æ³¨ï¼Œä»…ä¾›å‚è€ƒï¼Œæœ€ç»ˆä»¥å¼€å‘è€…åˆ†æä¸ºä¸»ã€‚**\r\n\r\n8. [å†å²ä¸Šçš„ good first issue åˆ—è¡¨](https://github.com/PaddlePaddle/community/tree/master/pfcc#good-first-issue)ï¼Œä¹Ÿæ¬¢è¿æ¥æ PR è§£å†³~ æ¬¢è¿è”ç³»èŠ±èŠ±åŠ å…¥ç¤¾åŒºï¼Œå’Œæˆ‘ä»¬ä¸€èµ·[å¿«ä¹å¼€æº](https://github.com/PaddlePaddle/Paddle/issues/48019)ï¼\r\n\r\n<img width=\"200\" alt=\"image\" src=\"https://user-images.githubusercontent.com/39876205/213131273-361d2bb8-ea48-4f62-9603-0b0401f50337.png\">\r\n",
        "state": "closed",
        "user": "zhwesky2010",
        "closed_by": "luotao1",
        "created_at": "2023-06-20T06:48:09+00:00",
        "updated_at": "2023-09-26T11:02:24+00:00",
        "closed_at": "2023-09-26T11:02:23+00:00",
        "comments_count": [
            "zhwesky2010",
            "zhwesky2010",
            "Atlantisming",
            "txyugood",
            "co63oc",
            "Liyulingyue",
            "luotao1",
            "Liyulingyue",
            "GreatV",
            "luotao1",
            "sanbuphy",
            "co63oc",
            "enkilee",
            "zhwesky2010",
            "zhwesky2010",
            "RedContritio",
            "RedContritio",
            "longranger2",
            "shuaills",
            "shuaills",
            "zhwesky2010",
            "mrcangye",
            "co63oc",
            "luotao1",
            "co63oc",
            "luotao1",
            "GreatV",
            "Liyulingyue",
            "Evan-master",
            "luotao1"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaConvert",
        "number": 267,
        "title": "torch.nn.functional.padæ— æ³•è½¬æ¢æˆåŠŸ",
        "body": "ç»“æœå¦‚ä¸‹ï¼š\r\n\r\n```python\r\n    def _relative_position_to_absolute_position(self, x):\r\n        \"\"\"\r\n        x: [b, h, l, 2*l-1]\r\n        ret: [b, h, l, l]\r\n        \"\"\"\r\n        batch, heads, length, _ = x.shape\r\n>>>        x = torch.nn.functional.pad(x, commons.convert_pad_shape([[0, 0], [\r\n            0, 0], [0, 0], [0, 1]]))\r\n        \"\"\"Class Method: *.view, can not convert, please check whether it is torch.Tensor.*/Optimizer.*/nn.Module.*/torch.distributions.Distribution.*/torch.autograd.function.FunctionCtx.*/torch.profiler.profile.*/torch.autograd.profiler.profile.*, and convert manually\"\"\"\r\n>>>        x_flat = x.view([batch, heads, length * 2 * length])\r\n>>>        x_flat = torch.nn.functional.pad(x_flat, commons.convert_pad_shape(\r\n            [[0, 0], [0, 0], [0, length - 1]]))\r\n        \"\"\"Class Method: *.view, can not convert, please check whether it is torch.Tensor.*/Optimizer.*/nn.Module.*/torch.distributions.Distribution.*/torch.autograd.function.FunctionCtx.*/torch.profiler.profile.*/torch.autograd.profiler.profile.*, and convert manually\"\"\"\r\n>>>        x_final = x_flat.view([batch, heads, length + 1, 2 * length - 1])[:,\r\n            :, :length, length - 1:]\r\n        return x_final\r\n\r\n    def _absolute_position_to_relative_position(self, x):\r\n        \"\"\"\r\n        x: [b, h, l, l]\r\n        ret: [b, h, l, 2*l-1]\r\n        \"\"\"\r\n        batch, heads, length, _ = x.shape\r\n>>>        x = torch.nn.functional.pad(x, commons.convert_pad_shape([[0, 0], [\r\n            0, 0], [0, 0], [0, length - 1]]))\r\n        \"\"\"Class Method: *.view, can not convert, please check whether it is torch.Tensor.*/Optimizer.*/nn.Module.*/torch.distributions.Distribution.*/torch.autograd.function.FunctionCtx.*/torch.profiler.profile.*/torch.autograd.profiler.profile.*, and convert manually\"\"\"\r\n>>>        x_flat = x.view([batch, heads, length ** 2 + length * (length - 1)])\r\n>>>        x_flat = torch.nn.functional.pad(x_flat, commons.convert_pad_shape(\r\n            [[0, 0], [0, 0], [length, 0]]))\r\n        \"\"\"Class Method: *.view, can not convert, please check whether it is torch.Tensor.*/Optimizer.*/nn.Module.*/torch.distributions.Distribution.*/torch.autograd.function.FunctionCtx.*/torch.profiler.profile.*/torch.autograd.profiler.profile.*, and convert manually\"\"\"\r\n>>>        x_final = x_flat.view([batch, heads, length, 2 * length])[:, :, :, 1:]\r\n        return x_final\r\n\r\n```",
        "state": "closed",
        "user": "yeyupiaoling",
        "closed_by": "yeyupiaoling",
        "created_at": "2023-09-01T15:11:45+00:00",
        "updated_at": "2024-04-03T05:53:16+00:00",
        "closed_at": "2024-04-03T05:53:16+00:00",
        "comments_count": [
            "zhwesky2010",
            "yeyupiaoling",
            "zhwesky2010",
            "yeyupiaoling",
            "yeyupiaoling",
            "zhwesky2010",
            "yeyupiaoling"
        ],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaConvert",
        "number": 519,
        "title": "æ–°éœ€æ±‚",
        "body": "èƒ½ä¸èƒ½æŠŠcheckpointè½¬æ¢ä¹Ÿåšäº†\r\næ¯”å¦‚ï¼šhttps://www.modelscope.cn/models/sentence-transformers/all-MiniLM-L6-v2/files\r\n",
        "state": "open",
        "user": "wangguan1995",
        "closed_by": null,
        "created_at": "2024-11-26T04:48:27+00:00",
        "updated_at": "2024-11-26T04:48:41+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaConvert",
        "number": 521,
        "title": "åœ¨åˆ—è¡¨æ¨å¯¼å¼ä¸­è½¬æ¢ torch API æ—¶æ— æ³•æ­£ç¡®æ’å…¥è¾…åŠ©ä»£ç ",
        "body": "## é—®é¢˜æè¿°\r\nå½“åœ¨åˆ—è¡¨æ¨å¯¼å¼ä¸­è½¬æ¢ torch API æ—¶ï¼Œç”±äº `BaseTransformer::insert_multi_node` çš„é™åˆ¶ï¼Œæ— æ³•æ­£ç¡®æ’å…¥å¿…è¦çš„è¾…åŠ©ä»£ç ï¼ˆå¦‚ import è¯­å¥å’Œ sys.path è®¾ç½®ï¼‰ã€‚\r\n**è¿™ä¸ªé—®é¢˜ä¼šå½±å“æ‰€æœ‰åœ¨åˆ—è¡¨æ¨å¯¼å¼æˆ–å­—å…¸æ¨å¯¼å¼ä¸­ä½¿ç”¨è¾…åŠ©å‡½æ•°çš„ torch API çš„ä»£ç è½¬æ¢ã€‚**\r\n\r\n## å¤ç°æ­¥éª¤\r\n1. è½¬æ¢å¦‚ä¸‹çš„ PyTorch ä»£ç ï¼š\r\n```python\r\nimport torch\r\na = torch.Tensor([[1.,2.], [3.,4.]])\r\nlist_a = [a,a]\r\nresult = [torch.transpose(input=x, dim1=0, dim0=1) for x in list_a ]\r\n```\r\n\r\n2. ä½¿ç”¨ PaConvert å¾—åˆ°çš„ Paddle ä»£ç ï¼š\r\n```python\r\nimport paddle\r\na = paddle.to_tensor(data=[[1.0, 2.0], [3.0, 4.0]], dtype='float32')\r\nlist_a = [a, a]\r\nresult = [paddle.transpose(x=x, perm=paddle_aux.transpose_aux_func(x.ndim, \r\n    1, 0)) for x in list_a]\r\n```\r\n**å…¶ä¸­æ²¡æœ‰æ­£å¸¸å¯¼å…¥ paddle_aux**\r\n\r\n## Bug åŸå› \r\nå½“è½¬æ¢å™¨å¤„ç†åˆ—è¡¨æ¨å¯¼å¼ä¸­çš„ `torch.transpose()` æ—¶ï¼Œéœ€è¦æ’å…¥è¾…åŠ©ä»£ç ã€‚ä½†æ˜¯ç”±äº `insert_multi_node` æ–¹æ³•ä¸­çš„å¦‚ä¸‹æ£€æŸ¥ï¼Œä¼šæ‹¦æˆªåœ¨åˆ—è¡¨æ¨å¯¼å¼ä¸­æ’å…¥æ–°èŠ‚ç‚¹ï¼š\r\n```python\r\nif isinstance(self.parent_node, (ast.DictComp, ast.ListComp)):\r\n    return False\r\n```\r\nå¯¼è‡´å¿…è¦çš„è¾…åŠ©ä»£ç æ— æ³•è¢«æ­£ç¡®æ’å…¥ã€‚\r\n\r\n## å¯èƒ½çš„ä¿®å¤æ–¹æ¡ˆ\r\nä¿®æ”¹ `insert_multi_node` æ–¹æ³•ï¼Œå°† import ç›¸å…³çš„èŠ‚ç‚¹ï¼ˆåŒ…æ‹¬ import è¯­å¥å’Œ sys.path è®¾ç½®ï¼‰å§‹ç»ˆæ’å…¥åˆ°æ–‡ä»¶é¡¶éƒ¨ï¼Œè€Œä¸å—æ¨å¯¼å¼ä½œç”¨åŸŸçš„é™åˆ¶ã€‚ä¾‹å¦‚ï¼š\r\n\r\n```python\r\ndef insert_multi_node(self, node_list):\r\n    if len(node_list) == 0:\r\n        return True\r\n\r\n    import_nodes = []\r\n    other_nodes = []\r\n    for node in node_list:\r\n        if isinstance(node, (ast.Import, ast.ImportFrom)):\r\n            import_nodes.append(node)\r\n        elif \"sys.path\" in astor.to_source(node):\r\n            import_nodes.append(node)\r\n        else:\r\n            other_nodes.append(node)\r\n\r\n    # å§‹ç»ˆå°†importç›¸å…³çš„èŠ‚ç‚¹æ’å…¥åˆ°æ–‡ä»¶é¡¶éƒ¨\r\n    if len(import_nodes) > 0:\r\n        self.record_scope((self.root, \"body\", 0), import_nodes)\r\n\r\n    # å…¶ä»–èŠ‚ç‚¹ä»ç„¶éµå¾ªåŸæ¥çš„é€»è¾‘\r\n    if len(other_nodes) > 0:\r\n        if isinstance(self.parent_node, (ast.DictComp, ast.ListComp)):\r\n            return False\r\n        self.record_scope(self.scope_body_index(), other_nodes)\r\n\r\n    return True\r\n```",
        "state": "closed",
        "user": "guozixu2001",
        "closed_by": "zhwesky2010",
        "created_at": "2024-11-27T03:10:03+00:00",
        "updated_at": "2024-11-29T11:46:09+00:00",
        "closed_at": "2024-11-29T11:46:09+00:00",
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaConvert",
        "number": 545,
        "title": "paconverä¼šè½¬requirementsé‡Œçš„torchå†…å®¹",
        "body": "å»ºè®®åªè½¬æ¢pyæ–‡ä»¶ï¼Œrequirements.txtä¸è¦åŠ¨ï¼Œæˆ–è€…å¢åŠ ä¸€è¡Œpaddlepaddle-gpu==0.0.0",
        "state": "open",
        "user": "wangguan1995",
        "closed_by": null,
        "created_at": "2025-01-20T06:43:55+00:00",
        "updated_at": "2025-01-20T06:43:55+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaConvert",
        "number": 541,
        "title": "å»ºè®®åŠ å…¥æ³¨é‡Šæ£€æµ‹",
        "body": "å»ºè®®åŠ å…¥æ³¨é‡Šæ£€æµ‹\r\næœ‰çš„æ—¶å€™æ£€æŸ¥ä»£ç ä¼šå‘ç°ï¼Œæœ‰çš„torchæ³¨é‡Šéƒ¨åˆ†å¿˜è®°åˆ é™¤äº†ï¼ŒåŠ ä¸Šä¼šæ›´å¥½",
        "state": "open",
        "user": "wangguan1995",
        "closed_by": null,
        "created_at": "2025-01-07T06:58:41+00:00",
        "updated_at": "2025-01-07T06:58:41+00:00",
        "closed_at": null,
        "comments_count": [],
        "labels": []
    },
    {
        "repo": "PaddlePaddle/PaConvert",
        "number": 371,
        "title": "è½¬æ¢å‡ºç°bug",
        "body": "- torch\r\n\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nfrom typing import List, Tuple, Optional\r\nimport math\r\n\r\n# Calculate asymmetric TensorFlow-like 'SAME' padding for a convolution\r\ndef get_same_padding(x: int, kernel_size: int, stride: int, dilation: int):\r\n    if isinstance(x, torch.Tensor):\r\n        return torch.clamp(((x / stride).ceil() - 1) * stride + (kernel_size - 1) * dilation + 1 - x, min=0)\r\n    else:\r\n        return max((math.ceil(x / stride) - 1) * stride + (kernel_size - 1) * dilation + 1 - x, 0)\r\n\r\n\r\n# Dynamically pad input x with 'SAME' padding for conv with specified args\r\ndef pad_same(\r\n        x,\r\n        kernel_size: List[int],\r\n        stride: List[int],\r\n        dilation: List[int] = (1, 1),\r\n        value: float = 0,\r\n):\r\n    ih, iw = x.size()[-2:]\r\n    pad_h = get_same_padding(ih, kernel_size[0], stride[0], dilation[0])\r\n    pad_w = get_same_padding(iw, kernel_size[1], stride[1], dilation[1])\r\n    x = F.pad(x, (pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2), value=value)\r\n    return x\r\n\r\n\r\ndef avg_pool2d_same(x, kernel_size: List[int], stride: List[int], padding: List[int] = (0, 0),\r\n                    ceil_mode: bool = False, count_include_pad: bool = True):\r\n    # FIXME how to deal with count_include_pad vs not for external padding?\r\n    x = pad_same(x, kernel_size, stride)\r\n    return F.avg_pool2d(x, kernel_size, stride, (0, 0), ceil_mode, count_include_pad)\r\n```\r\n- paddlepaddle\r\n\r\n```python\r\nimport sys\r\nsys.path.append('/home/greatx/repos/PaConvert/paddle_project/utils')\r\nimport paddle_aux\r\nimport paddle\r\nfrom typing import List, Tuple, Optional\r\nimport math\r\n\r\n\r\ndef get_same_padding(x: int, kernel_size: int, stride: int, dilation: int):\r\n    if isinstance(x, paddle.Tensor):\r\n        return paddle.clip(x=((x / stride).ceil() - 1) * stride + (\r\n            kernel_size - 1) * dilation + 1 - x, min=0)\r\n    else:\r\n        return max((math.ceil(x / stride) - 1) * stride + (kernel_size - 1) *\r\n            dilation + 1 - x, 0)\r\n\r\n\r\ndef pad_same(x, kernel_size: List[int], stride: List[int], dilation: List[\r\n    int]=(1, 1), value: float=0):\r\n    ih, iw = x.shape[-2:]\r\n    pad_h = get_same_padding(ih, kernel_size[0], stride[0], dilation[0])\r\n    pad_w = get_same_padding(iw, kernel_size[1], stride[1], dilation[1])\r\n    x = paddle_aux._FUNCTIONAL_PAD(pad=(pad_w // 2, pad_w - pad_w // 2, \r\n        pad_h // 2, pad_h - pad_h // 2), value=value, x=x)\r\n    return x\r\n\r\n\r\ndef avg_pool2d_same(x, kernel_size: List[int], stride: List[int], padding:\r\n    List[int]=(0, 0), ceil_mode: bool=False, count_include_pad: bool=True):\r\n    x = pad_same(x, kernel_size, stride)\r\n    return paddle.nn.functional.avg_pool2d(kernel_size=kernel_size, stride=\r\n        stride, padding=(0, 0), ceil_mode=ceil_mode, x=x, exclusive=\r\n        notcount_include_pad)\r\n```\r\n\r\n`count_include_pad` -> `not count_include_pad` -> `notcount_include_pad`",
        "state": "closed",
        "user": "GreatV",
        "closed_by": "GreatV",
        "created_at": "2024-02-25T03:11:59+00:00",
        "updated_at": "2024-03-14T08:52:30+00:00",
        "closed_at": "2024-03-14T08:52:30+00:00",
        "comments_count": [
            "zhwesky2010"
        ],
        "labels": [
            "PFCC"
        ]
    },
    {
        "repo": "PaddlePaddle/PaConvert",
        "number": 364,
        "title": "got wrong output",
        "body": "```shell\r\n git clone https://github.com/facebookresearch/detectron2.git\r\ncd PaConvert\r\npython paconvert/main.py --in_dir ../detectron2/ --out_dir ../detectron2.paddle\r\n```\r\n\r\n- original:  [detectron2](https://github.com/facebookresearch/detectron2/tree/main)/[detectron2](https://github.com/facebookresearch/detectron2/tree/main/detectron2)/[utils](https://github.com/facebookresearch/detectron2/tree/main/detectron2/utils)/comm.py\r\n```python\r\n# Copyright (c) Facebook, Inc. and its affiliates.\r\n\"\"\"\r\nThis file contains primitives for multi-gpu communication.\r\nThis is useful when doing distributed training.\r\n\"\"\"\r\n\r\nimport functools\r\nimport numpy as np\r\nimport torch\r\nimport torch.distributed as dist\r\n\r\n_LOCAL_PROCESS_GROUP = None\r\n_MISSING_LOCAL_PG_ERROR = (\r\n    \"Local process group is not yet created! Please use detectron2's `launch()` \"\r\n    \"to start processes and initialize pytorch process group. If you need to start \"\r\n    \"processes in other ways, please call comm.create_local_process_group(\"\r\n    \"num_workers_per_machine) after calling torch.distributed.init_process_group().\"\r\n)\r\n\r\n```\r\n\r\n- Converted: detectron2.paddle/detectron2/utils/comm.py\r\n\r\n```python\r\nimport paddle\r\n\"\"\"\r\nThis file contains primitives for multi-gpu communication.\r\nThis is useful when doing distributed training.\r\n\"\"\"\r\nimport functools\r\nimport numpy as np\r\n_LOCAL_PROCESS_GROUP = None\r\n_MISSING_LOCAL_PG_ERROR = (\r\n>>>>>>    \"Local process group is not yet created! Please use detectron2's `launch()` to start processes and initialize pytorch process group. If you need to start processes in other ways, please call comm.create_local_process_group(num_workers_per_machine) after calling torch.distributed.init_process_group().\"\r\n    )\r\n\r\n```",
        "state": "closed",
        "user": "GreatV",
        "closed_by": "GreatV",
        "created_at": "2024-02-05T02:28:43+00:00",
        "updated_at": "2024-03-14T07:50:54+00:00",
        "closed_at": "2024-03-14T07:50:54+00:00",
        "comments_count": [
            "zhwesky2010"
        ],
        "labels": [
            "PFCC"
        ]
    }
]