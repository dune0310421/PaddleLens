{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6769a54e",
   "metadata": {},
   "source": [
    "#### 获取paddle所有repo的commits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9883c4e",
   "metadata": {},
   "source": [
    "方法1：使用git log获取，然后转换为json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a248edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "# 读取repo文件，循环处理每个repo\n",
    "cat ./data/paddle_repo.json | jq -c '.[]' | while read repo_info; do\n",
    "    FULL_NAME=$(echo $repo_info | jq -r '.full_name')    \n",
    "    REPO_URL=\"https://github.com/$FULL_NAME.git\"    \n",
    "    FILE_NAME=$(echo $FULL_NAME | tr '/' '_')\n",
    "    \n",
    "    # 指定目录，clone repo\n",
    "    DEST_DIR=\"./repos\"\n",
    "    mkdir -p $DEST_DIR\n",
    "    CLONE_PATH=\"$DEST_DIR/$FILE_NAME\"    \n",
    "    git clone $REPO_URL $CLONE_PATH\n",
    "\n",
    "    # 获取commit日志\n",
    "    cd $CLONE_PATH\n",
    "    git log --pretty=format:'{\"repo\": \"'\"$FULL_NAME\"'\", \"sha\": \"%H\", \"created_at\": \"%ad\", \"author\": \"%an\", \"committer\": \"%cn\", \"message\": \"%f\"},' --date=iso | sed \"$ s/,$//\" > ../${FILE_NAME}_commits.json\n",
    "    git log --name-status --pretty=format:'STARTOFTHECOMMIT\\nsha: %H'> ../${FILE_NAME}_commits1.log\n",
    "    git log --numstat --pretty=format:'STARTOFTHECOMMIT\\nsha: %H'> ../${FILE_NAME}_commits2.log\n",
    "\n",
    "    cd ../.. # 返回当前目录\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4018d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: PaddlePaddle/Paddle-Lite\n",
      "Processing repository: PaddlePaddle/PaddleSpeech\n",
      "Processing repository: PaddlePaddle/VisualDL\n",
      "Processing repository: PaddlePaddle/continuous_evaluation\n",
      "Processing repository: PaddlePaddle/Paddle2ONNX\n",
      "Processing repository: PaddlePaddle/paddle-ce-latest-kpis\n",
      "Processing repository: PaddlePaddle/PARL\n",
      "Processing repository: PaddlePaddle/Anakin\n",
      "Processing repository: PaddlePaddle/docs\n",
      "Processing repository: PaddlePaddle/tape\n",
      "Processing repository: PaddlePaddle/PaddleFleetX\n",
      "Processing repository: PaddlePaddle/PaddleFormers\n",
      "Processing repository: PaddlePaddle/X2Paddle\n",
      "Processing repository: PaddlePaddle/AutoDL\n",
      "Processing repository: PaddlePaddle/benchmark\n",
      "Processing repository: PaddlePaddle/ERNIE\n",
      "Processing repository: PaddlePaddle/Serving\n",
      "Processing repository: PaddlePaddle/any\n",
      "Processing repository: PaddlePaddle/PGL\n",
      "Processing repository: PaddlePaddle/MetaGym\n",
      "Processing repository: PaddlePaddle/Paddle-Lite-Demo\n",
      "Processing repository: PaddlePaddle/epep\n",
      "Processing repository: PaddlePaddle/examples\n",
      "Processing repository: PaddlePaddle/PaddleSeg\n",
      "Processing repository: PaddlePaddle/PALM\n",
      "Processing repository: PaddlePaddle/PaddleFL\n",
      "Processing repository: PaddlePaddle/PaddleDetection\n",
      "Processing repository: PaddlePaddle/PaddleCraft\n",
      "Processing repository: PaddlePaddle/ElasticCTR\n",
      "Processing repository: PaddlePaddle/awesome-DeepLearning\n",
      "Processing repository: PaddlePaddle/PLSC\n",
      "Processing repository: PaddlePaddle/PaddleSlim\n",
      "Processing repository: PaddlePaddle/hapi\n",
      "Processing repository: PaddlePaddle/CINN\n",
      "Processing repository: PaddlePaddle/Research\n",
      "Processing repository: PaddlePaddle/Contrib\n",
      "Processing repository: PaddlePaddle/Parakeet\n",
      "Processing repository: PaddlePaddle/continuous_integration\n",
      "Processing repository: PaddlePaddle/PaddleX\n",
      "Processing repository: PaddlePaddle/Paddle.js\n",
      "Processing repository: PaddlePaddle/PaddleClas\n",
      "Processing repository: PaddlePaddle/Paddle-bot\n",
      "Processing repository: PaddlePaddle/PaddleRec\n",
      "Processing repository: PaddlePaddle/Paddle-Inference-Demo\n",
      "Processing repository: PaddlePaddle/PaddleOCR\n",
      "Processing repository: PaddlePaddle/Quantum\n",
      "Processing repository: PaddlePaddle/PaddleGAN\n",
      "Processing repository: PaddlePaddle/InterpretDL\n",
      "Processing repository: PaddlePaddle/Knover\n",
      "Processing repository: PaddlePaddle/paddle_upgrade_tool\n",
      "Processing repository: PaddlePaddle/community\n",
      "Processing repository: PaddlePaddle/LiteKit\n",
      "Processing repository: PaddlePaddle/PaddleVideo\n",
      "Processing repository: PaddlePaddle/PaddleHelix\n",
      "Processing repository: PaddlePaddle/PaddleRobotics\n",
      "Processing repository: PaddlePaddle/Perf\n",
      "Processing repository: PaddlePaddle/PASSL\n",
      "Processing repository: PaddlePaddle/PaddleNLP\n",
      "Processing repository: PaddlePaddle/PaddleSleeve\n",
      "Processing repository: PaddlePaddle/PaddleTest\n",
      "Processing repository: PaddlePaddle/PaddleSpatial\n",
      "Processing repository: PaddlePaddle/RocketQA\n",
      "Processing repository: PaddlePaddle/VIMER\n",
      "Processing repository: PaddlePaddle/PaddleScience\n",
      "Processing repository: PaddlePaddle/PaddleDTX\n",
      "Processing repository: PaddlePaddle/PaddleFlow\n",
      "Processing repository: PaddlePaddle/TrustAI\n",
      "Processing repository: PaddlePaddle/PaddleCustomDevice\n",
      "Processing repository: PaddlePaddle/PaddleTransfer\n",
      "Processing repository: PaddlePaddle/PaddleTS\n",
      "Processing repository: PaddlePaddle/FastDeploy\n",
      "Processing repository: PaddlePaddle/PaddleYOLO\n",
      "Processing repository: PaddlePaddle/Paddle3D\n",
      "Processing repository: PaddlePaddle/PaddleRS\n",
      "Processing repository: PaddlePaddle/PaddleSports\n",
      "Processing repository: PaddlePaddle/FlyCV\n",
      "Processing repository: PaddlePaddle/PaddleDepth\n",
      "Processing repository: PaddlePaddle/EasyData\n",
      "Processing repository: PaddlePaddle/warp-transducer\n",
      "Processing repository: PaddlePaddle/PaDiff\n",
      "Processing repository: PaddlePaddle/flash-attention\n",
      "Processing repository: PaddlePaddle/PaConvert\n",
      "Processing repository: PaddlePaddle/PaddleSOT\n",
      "Processing repository: PaddlePaddle/PaddleMIX\n",
      "Processing repository: PaddlePaddle/ERNIE-SDK\n",
      "Processing repository: PaddlePaddle/modulus\n",
      "Processing repository: PaddlePaddle/modulus-sym\n",
      "Processing repository: PaddlePaddle/Athena\n",
      "Processing repository: PaddlePaddle/PaddleAPEX\n",
      "Processing repository: PaddlePaddle/PaddleMaterial\n",
      "Processing repository: PaddlePaddle/PaddleSecurityTest\n",
      "Processing repository: PaddlePaddle/flux\n",
      "Processing repository: PaddlePaddle/PaddleHub\n",
      "Processing repository: PFCCLab/dochooks\n",
      "Processing repository: PFCCLab/release-notes-drafter\n",
      "Processing repository: PFCCLab/mydynamo\n",
      "Processing repository: PFCCLab/fool-proof-paddle-installation\n",
      "Processing repository: PFCCLab/paddlefx\n",
      "Processing repository: PFCCLab/paddle-cpp-demo\n",
      "Processing repository: PFCCLab/PaddleAutoProject\n",
      "Processing repository: PFCCLab/paddle-cpp-train\n",
      "Processing repository: PFCCLab/paddleviz\n",
      "Processing repository: PFCCLab/Camp\n",
      "Processing repository: PFCCLab/Starter\n",
      "Processing repository: PFCCLab/pfcclab.github.io\n",
      "Processing repository: PFCCLab/blog\n",
      "Processing repository: PFCCLab/xla\n",
      "Processing repository: PFCCLab/cmake-lint-paddle\n",
      "Processing repository: PFCCLab/docs-next\n",
      "Processing repository: PFCCLab/dokyu\n",
      "Processing repository: PFCCLab/PaddleLabel-Frontend\n",
      "Processing repository: PFCCLab/PaddleLabel-ML\n",
      "Processing repository: PFCCLab/PaddleLabel\n",
      "Processing repository: PFCCLab/PPOCRLabel\n",
      "Processing repository: PFCCLab/StyleText\n",
      "Processing repository: PFCCLab/netron\n",
      "Processing repository: PFCCLab/deepali\n",
      "Processing repository: PFCCLab/Open3D\n",
      "Processing repository: PFCCLab/typos-pre-commit-mirror\n",
      "Processing repository: PFCCLab/paddle_harmonics\n",
      "Processing repository: PFCCLab/neuraloperator\n",
      "Processing repository: PFCCLab/ci-bypass\n",
      "Processing repository: PFCCLab/PaddleAPITest\n",
      "Processing repository: PFCCLab/paddle_scatter\n",
      "Processing repository: PFCCLab/PaddlePaddle-Contributors-Wall\n",
      "Processing repository: PFCCLab/paddle-annual-report\n",
      "Processing repository: PFCCLab/google-yamlfmt\n",
      "Processing repository: PFCCLab/yamlfmt-pre-commit-mirror\n",
      "Processing repository: PFCCLab/paddle_sparse\n",
      "Processing repository: PFCCLab/PaddleDownstreamAnalysis\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_commit_objects(file_path):\n",
    "    \"\"\"\n",
    "    将git log获取的commit基本信息转换为json\n",
    "    \"\"\"\n",
    "    commits = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                # 将每一行的JSON对象加载为Python字典\n",
    "                line = line.strip().rstrip(',')\n",
    "                commit = json.loads(line)\n",
    "                commits.append(commit)\n",
    "    return commits\n",
    "\n",
    "def extract_new_filename(change_str):\n",
    "    \"\"\"\n",
    "    修改文件名的文件保留新的文件名\n",
    "    如'demo/components/{pir_translate.py => pir_program_test.py}'\n",
    "    \"\"\"\n",
    "    start = change_str.find('=>') + 3  # Skip '=> ' to get to the new filename\n",
    "    end = change_str.find('}', start)\n",
    "\n",
    "    new_filename = change_str[start:end].strip()\n",
    "\n",
    "    base_path = change_str[:change_str.find('{')].strip()\n",
    "    return f\"{base_path}{new_filename}\"\n",
    "\n",
    "def parse_commit_logs1(file_path):\n",
    "    \"\"\"\n",
    "    解析git log --name-status获取的commit信息\n",
    "    \"\"\"\n",
    "    commit_data = {}\n",
    "    current_sha = None\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"STARTOFTHECOMMIT\"):\n",
    "                current_sha = line.split(\": \")[1]\n",
    "                commit_data[current_sha] = {'files': []}\n",
    "            else:\n",
    "                if line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) == 2:\n",
    "                        status, filename = parts[0], parts[1]\n",
    "                        if status == 'A':\n",
    "                            status = 'added'\n",
    "                        elif status == 'M':\n",
    "                            status = 'modified'\n",
    "                        else:\n",
    "                            status = 'removed'\n",
    "                        commit_data[current_sha]['files'].append({\n",
    "                            'filename': filename,\n",
    "                            'status': status,\n",
    "                        })\n",
    "                    elif len(parts) == 3:\n",
    "                        status, filename = parts[0], parts[2]\n",
    "                        commit_data[current_sha]['files'].append({\n",
    "                            'filename': filename,\n",
    "                            'status': 'modified',\n",
    "                        })\n",
    "    return commit_data\n",
    "\n",
    "def parse_commit_logs2(file_path):\n",
    "    \"\"\"\n",
    "    解析git log --numstat获取的commit信息\n",
    "    \"\"\"\n",
    "    commit_data = {}\n",
    "    current_sha = None\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"STARTOFTHECOMMIT\"):\n",
    "                current_sha = line.split(\": \")[1]\n",
    "                commit_data[current_sha] = {'files': []}\n",
    "            else:\n",
    "                if line:\n",
    "                    parts = line.split()\n",
    "                    # print(line)\n",
    "                    additions = int(parts[0]) if parts[0].isdigit() else 0\n",
    "                    deletions = int(parts[1]) if parts[1].isdigit() else 0\n",
    "                    # filename = extract_new_filename(parts[2]) if \"=>\" in parts[2] else parts[2]\n",
    "                    commit_data[current_sha]['files'].append({\n",
    "                        # 'filename': filename,\n",
    "                        'additions': additions,\n",
    "                        'deletions': deletions,\n",
    "                        'changes': additions + deletions\n",
    "                        })\n",
    "    return commit_data\n",
    "\n",
    "\n",
    "repos = None\n",
    "with open(\"data/tmp.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    repos = json.load(f)\n",
    "\n",
    "for repo in repos:\n",
    "    repo_owner_repo = repo['full_name']\n",
    "    print(f\"Processing repository: {repo_owner_repo}\")\n",
    "\n",
    "    commits_file = f\"repos/{repo_owner_repo.replace('/', '_')}_commits.json\"\n",
    "    commits1_file = f\"repos/{repo_owner_repo.replace('/', '_')}_commits1.log\"\n",
    "    commits2_file = f\"repos/{repo_owner_repo.replace('/', '_')}_commits2.log\"\n",
    "    commits = load_commit_objects(commits_file)\n",
    "    commit_details_1 = parse_commit_logs1(commits1_file)\n",
    "    commit_details_2 = parse_commit_logs2(commits2_file)\n",
    "\n",
    "    # 合并信息\n",
    "    final_commit_details = []\n",
    "    for commit in commits:\n",
    "        sha = commit['sha']\n",
    "        files_1 = commit_details_1.get(sha, {}).get('files', [])\n",
    "        files_2 = commit_details_2.get(sha, {}).get('files', [])\n",
    "\n",
    "        for i in range(len(files_1)):\n",
    "            file_1 = files_1[i]\n",
    "            file_2 = files_2[i] if i < len(files_2) else {}\n",
    "            file_1.update(file_2)\n",
    "\n",
    "        commit['files'] = files_1\n",
    "        final_commit_details.append(commit)\n",
    "\n",
    "    repo_owner, repo_name = repo['full_name'].split('/')\n",
    "    output_filename = f\"data/paddle_commits/{repo_owner}_{repo_name}_commits.json\"\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(final_commit_details, f, indent=4)\n",
    "\n",
    "    # print(f\"Merged data for {repo_owner_repo} into {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01026f88",
   "metadata": {},
   "source": [
    "方法2：使用github api获取，相对更慢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f10b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.request_github import request_github\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import json\n",
    "from github import Github\n",
    "# import requests\n",
    "\n",
    "def get_repo_commits(gh, repo):\n",
    "    \"\"\"\n",
    "    获取指定仓库的所有commit\n",
    "    \"\"\"\n",
    "    commits = request_github(\n",
    "        gh, lambda r: gh.get_repo(r).get_commits(),\n",
    "        (repo['full_name'], )\n",
    "    )\n",
    "    logger.info(f\"Fetching commits for repository: {repo['full_name']}, total: {commits.totalCount}\")\n",
    "\n",
    "    commit_list = []\n",
    "    for commit in tqdm(commits):\n",
    "        try:\n",
    "            commit_info = {\n",
    "                'repo': repo['full_name'],\n",
    "                'sha': commit.sha,\n",
    "                'message': commit.commit.message,\n",
    "                'created_at': commit.commit.author.date.isoformat(),\n",
    "                'author': commit.author.login if commit.author else None,\n",
    "                'committer': commit.committer.login if commit.committer else None,\n",
    "            }\n",
    "            commit_files = commit.files\n",
    "            if commit_files:\n",
    "                commit_info['files'] = []\n",
    "                for file in commit_files:\n",
    "                    file_info = {\n",
    "                        'filename': file.filename,\n",
    "                        'status': file.status,\n",
    "                        'additions': file.additions,\n",
    "                        'deletions': file.deletions,\n",
    "                        'changes': file.changes,\n",
    "                        # 'patch': file.patch if hasattr(file, 'patch') else None\n",
    "                    }\n",
    "                    commit_info['files'].append(file_info)\n",
    "            else:\n",
    "                commit_info['files'] = []\n",
    "            commit_list.append(commit_info)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing commit {commit.sha} in repository {repo['full_name']}: {e}\")\n",
    "            commit_list.append({\n",
    "                'repo': repo['full_name'],\n",
    "                'sha': commit.sha,\n",
    "                'error': str(e)\n",
    "            })\n",
    "            continue\n",
    "    return commit_list\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s (PID %(process)d) [%(levelname)s] %(filename)s:%(lineno)d %(message)s\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "token = '' # 添加你的GitHub token\n",
    "gh = Github(token)\n",
    "\n",
    "with open(\"data/paddle_repos.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    repos = json.load(f)\n",
    "\n",
    "for repo in repos:\n",
    "    # 获取每个仓库的commit信息\n",
    "    commits = get_repo_commits(gh, repo)\n",
    "    repo_owner, repo_name = repo['full_name'].split('/')\n",
    "    with open(f\"data/paddle_commits/{repo_owner}_{repo_name}_commits.json\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        json.dump(commits, f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "downstream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
